{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import binom\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def generate_blob(grid_size, blob_radius, jitter):\n",
    "    \"\"\"Generate a single blob with random jitter.\"\"\"\n",
    "    center = np.random.randint(blob_radius, grid_size - blob_radius, size=2) + jitter\n",
    "    y, x = np.ogrid[-center[0]:grid_size-center[0], -center[1]:grid_size-center[1]]\n",
    "    mask = x**2 + y**2 <= blob_radius**2\n",
    "    blob = np.zeros((grid_size, grid_size))\n",
    "    blob[mask] = 1\n",
    "    return blob\n",
    "\n",
    "def generate_map(grid_size, max_blobs, jitter):\n",
    "    \"\"\"Generate a spatial map with blobs and jitter.\"\"\"\n",
    "    map = np.zeros((grid_size, grid_size))\n",
    "    num_blobs = binom.rvs(n=3, p=0.5, size=1)[0]  # Binomial distribution for number of blobs\n",
    "    blob_radii = np.random.randint(5, 15, size=num_blobs)  # Random radius for each blob\n",
    "\n",
    "    for _ in range(max_blobs):\n",
    "        if num_blobs > 0:\n",
    "            radius = np.random.choice(blob_radii)\n",
    "            blob = generate_blob(grid_size, radius, jitter)\n",
    "            map += blob  # Add blob to the map\n",
    "\n",
    "    return map\n",
    "\n",
    "def generate_synthetic_fmri_data(subjects, maps_per_subject, time_points, grid_size):\n",
    "    \"\"\"Generate synthetic fMRI data for multiple subjects.\"\"\"\n",
    "    data = np.zeros((subjects, maps_per_subject, grid_size, grid_size, time_points))\n",
    "\n",
    "    for subject in range(subjects):\n",
    "        jitter = np.random.normal(0, 1, 2)  # Gaussian-distributed jitter\n",
    "        for map_index in range(maps_per_subject):\n",
    "            spatial_map = generate_map(grid_size, max_blobs=3, jitter=jitter)\n",
    "            for time_point in range(time_points):\n",
    "                time_series = np.random.rand(grid_size, grid_size)\n",
    "                noise = gaussian_filter(np.random.randn(grid_size, grid_size), sigma=3)\n",
    "                data[subject, map_index, :, :, time_point] = spatial_map * time_series + noise\n",
    "\n",
    "    return data\n",
    "\n",
    "# Parameters\n",
    "subjects = 12\n",
    "maps_per_subject = 5\n",
    "time_points = 150\n",
    "grid_size = 50\n",
    "\n",
    "# Generate synthetic fMRI data\n",
    "synthetic_data = generate_synthetic_fmri_data(subjects, maps_per_subject, time_points, grid_size)\n",
    "\n",
    "# Visualize one of the generated maps\n",
    "plt.imshow(synthetic_data[0, 3, :, :, 0], cmap='gray')\n",
    "plt.title(\"Sample Synthetic fMRI Map\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "\n",
    "def compute_energy(Us,Vs,V,mu,lambda_r, regularization_fun, ):\n",
    "    S = len(Us)  # Number of subjects\n",
    "    energy = 0\n",
    "    for s in range(S):\n",
    "        term1 = np.linalg.norm(Ys[s] - Us[s] @ Vs.T, 'fro')**2\n",
    "        term2 = mu * np.linalg.norm(Vs - V, 'fro')**2\n",
    "        energy += 0.5 * (term1 + term2)\n",
    "    \n",
    "    regularizer = regularization_fun(V) \n",
    "\n",
    "    energy += lambda_r * regularizer\n",
    "    return energy\n",
    "    \n",
    "def prox(V):\n",
    "    return V\n",
    "\n",
    "def update_vs(V ,Vs,Us ,Ys , mu):\n",
    "    # Mettre à jour Vs en utilisant la régression ridge\n",
    "    id = np.identity(Us.shape[1])\n",
    "    Vs = V + (Ys-Us@Vs.T)@ Us@ np.linalg.inv(Us.T@Us + mu * id )\n",
    "    return Vs\n",
    "\n",
    "def update_us(Ys, Vs, u_l):\n",
    "    u_l_new = u_l + np.linalg.norm(u_l, 2)**-2 * (Ys - u_l @ Vs.T @ Vs)\n",
    "    u_l_new = u_l_new / max(np.linalg.norm(u_l_new, 2), 1)\n",
    "    return u_l_new\n",
    "    \n",
    "\n",
    "def algorithm(Ys,V, k, mu, lambda_r, max_iter=1000, tolerance=1e-4):\n",
    "\n",
    "    n,p = Ys.shape  # n number of time points, p number of voxels \n",
    "    S = len(Ys)     # S number of subjects\n",
    "    \n",
    "    V = np.random.rand(p, k)  # group level spatial maps\n",
    "    Vs = [np.random.rand(p, k) for _ in range(S)]  # subject specific spatial maps\n",
    "    Us = [np.random.rand(n, k) for _ in range(S)]  # time series\n",
    "    E_old = float('inf')\n",
    "    E_new = compute_energy(Us, V)\n",
    "\n",
    "    i = 0\n",
    "    while np.abs(E_new - E_old) > tolerance * E_old and i < max_iter:\n",
    "        E_old = E_new\n",
    "        \n",
    "        # Update each U^s\n",
    "        for s in range(S):\n",
    "            for l in range(k):\n",
    "                Us[s][:, l] = update_us(Ys[s], V, Us[s][:, l])\n",
    "                \n",
    "            Vs = update_vs(Ys[s], Us[s], V, mu)\n",
    "            \n",
    "        Vs_mean = statistics.mean(Vs)\n",
    "        # Apply the proximal operator to the mean of every subject spatial maps\n",
    "        V = prox(Vs_mean, lambda_r)\n",
    "        \n",
    "        # Compute the energy\n",
    "        E_new = compute_energy(Us, V)\n",
    "        i += 1\n",
    "    \n",
    "    return V,Vs,Us"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
